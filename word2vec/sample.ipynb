{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 入力 1\n",
    "p. 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ナイトクラブ 0.583662748336792\n",
      "ヌード 0.5530823469161987\n",
      "スクラッグス 0.5426580905914307\n",
      "サロン 0.541516125202179\n",
      "パーティー 0.5277104377746582\n",
      "ダンサー 0.5097211003303528\n",
      "ジョー・ミーク 0.5076866745948792\n",
      "ストリップ 0.5030403733253479\n",
      "踊り子 0.49707716703414917\n",
      "ショー 0.49362289905548096\n"
     ]
    }
   ],
   "source": [
    "# Word2Vecモデルの初期化\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec.load('word2vec.gensim.model')\n",
    "\n",
    "# 特徴量ベクトルの取得\n",
    "v1 = model.wv['女王']\n",
    "v2 = model.wv['王']\n",
    "\n",
    "# 類似単語の取得\n",
    "v3 = v1 - v2\n",
    "for word, score in model.wv.most_similar([v3], topn=10):\n",
    "    print(word, score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 入力 2\n",
    "pp.49-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import twitter, oauthlib\n",
    "# ハードコーディングしてもよいがここで指定しても良い\n",
    "twitter.oauth_client = oauthlib.oauth1.Client(\n",
    "    '*********************',\n",
    "    client_secret='******************************************',\n",
    "    resource_owner_key = '**************************************************',\n",
    "    resource_owner_secret = '*****************************************'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet数: 50\n",
      "総単語数: 7248\n",
      "Unique 単語数: 561\n",
      "た     25\n",
      "に     24\n",
      "@     24\n",
      "だ     24\n",
      "て     23\n",
      "する    18\n",
      "。     18\n",
      "が     17\n",
      "ない    17\n",
      "の     17\n",
      "Name: 原型, dtype: int64\n",
      "経過時間: 10.254461526870728 s\n"
     ]
    }
   ],
   "source": [
    "import time, pandas as pd, mecabwrapper\n",
    "\n",
    "# 時間計測\n",
    "start = time.time()\n",
    "\n",
    "# 取得Tweet数\n",
    "N = 50\n",
    "print('Tweet数: {}'.format(N))\n",
    "\n",
    "# DataFrameを結合する\n",
    "df = pd.concat([\n",
    "\n",
    "    #Tweetの本文(text)中の単語を分解したDataFrameを得る。\n",
    "    mecabwrapper.parseText(tw['text'])\n",
    "      #日本語TweetをN個取得する。\n",
    "      for tw in twitter.get_sample_tweet(N, lambda x:x.get('lang') == 'ja')\n",
    "        \n",
    "])\n",
    "\n",
    "# 総単語数はdfの行数\n",
    "print('総単語数: {}'.format(df.size))\n",
    "\n",
    "# ユニーク単語数を数える\n",
    "print('Unique 単語数: {}'.format(df['原型'].nunique()))\n",
    "\n",
    "# 上位10個のカウントを表示\n",
    "print(df['原型'].value_counts().head(10))\n",
    "\n",
    "# 時間計測\n",
    "end = time.time()\n",
    "print('経過時間: {} s'.format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 入力 3\n",
    "p. 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "する         18\n",
      "HTTPS      14\n",
      "co         14\n",
      "ReTweet    12\n",
      "なる          7\n",
      "思う          7\n",
      "好き          6\n",
      "できる         4\n",
      "どう          4\n",
      "いい          3\n",
      "Name: 原型, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import tweetanalysis\n",
    "print(tweetanalysis.filter_words(df)['原型'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 入力 4\n",
    "p. 54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 本文では1000としたが、あまりに時間がかかるので50くらいで\n",
    "\n",
    "N = 50\n",
    "sample_tweets = twitter.get_sample_tweet(N, tweetanalysis.filter_tweet)\n",
    "sample_tweets = [*tweetanalysis.parse_tweet_list(sample_tweets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expectation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>する</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>俺</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>なる</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ない</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>垢</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>自分</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>みずき</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>こんな</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>愛す</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>爆撃</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     expectation\n",
       "する             9\n",
       "俺              5\n",
       "なる             4\n",
       "ない             4\n",
       "垢              3\n",
       "自分             2\n",
       "みずき            2\n",
       "こんな            2\n",
       "愛す             2\n",
       "爆撃             2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = len(sample_tweets)\n",
    "word_expectation = tweetanalysis.filter_words(\n",
    "    pd.concat(sample_tweets)\n",
    ")['原型'].value_counts(\n",
    ").to_frame('expectation').loc[\n",
    "    lambda x:x.index.map(model.__contains__)\n",
    "]\n",
    "\n",
    "display(word_expectation.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際に遊ぶにあたって、集計済みデータを用いたほうが精度が高いと思われる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('word_expectation.db')\n",
    "try:\n",
    "    expectation = pd.read_sql('SELECT * FROM expectation', conn).set_index('word')\n",
    "finally:\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 入力 5\n",
    "p. 57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "取得 Tweet数: 680\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>expectation</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>する</th>\n",
       "      <td>535</td>\n",
       "      <td>202.803660</td>\n",
       "      <td>276.027095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>局所</th>\n",
       "      <td>20</td>\n",
       "      <td>0.005847</td>\n",
       "      <td>221.256419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>東工大</th>\n",
       "      <td>20</td>\n",
       "      <td>0.006977</td>\n",
       "      <td>215.907024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>改ざん</th>\n",
       "      <td>15</td>\n",
       "      <td>0.005590</td>\n",
       "      <td>163.985173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>円グラフ</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>161.759854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>正しい</th>\n",
       "      <td>30</td>\n",
       "      <td>0.363158</td>\n",
       "      <td>158.471954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>最適</th>\n",
       "      <td>20</td>\n",
       "      <td>0.072241</td>\n",
       "      <td>145.180905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>比例</th>\n",
       "      <td>15</td>\n",
       "      <td>0.031231</td>\n",
       "      <td>124.306418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>値</th>\n",
       "      <td>15</td>\n",
       "      <td>0.033007</td>\n",
       "      <td>123.032107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>入試</th>\n",
       "      <td>15</td>\n",
       "      <td>0.034207</td>\n",
       "      <td>122.209923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        N  expectation       score\n",
       "する    535   202.803660  276.027095\n",
       "局所     20     0.005847  221.256419\n",
       "東工大    20     0.006977  215.907024\n",
       "改ざん    15     0.005590  163.985173\n",
       "円グラフ   10     0.000184  161.759854\n",
       "正しい    30     0.363158  158.471954\n",
       "最適     20     0.072241  145.180905\n",
       "比例     15     0.031231  124.306418\n",
       "値      15     0.033007  123.032107\n",
       "入試     15     0.034207  122.209923"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#解析対象ユーザを指定\n",
    "screen_name = '******'\n",
    "\n",
    "tweets_score, N = tweetanalysis.get_tweets_score(\n",
    "    screen_name,\n",
    "    expectation,\n",
    "    model\n",
    ")\n",
    "tweets_score.sort_values(\n",
    "    's\n",
    "    ascending=False,\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "print('取得 Tweet数: {}'.format(N))\n",
    "display(tweets_score.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 入力 6\n",
    "p. 59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gjhdvhd\n",
      "['振舞', '受け手', '安全率', '荒らし行為', '物事', '理屈', '矛盾許容論理', 'ディザ', '人身攻撃', '受身']\n",
      "ha_chu\n",
      "['大切な人', '好きな人', '飲み会', '恋愛相談', 'お手伝い', 'お客さん', 'お話', '若い人', '人生相談', '追っかけ']\n",
      "ariyoshihiroiki\n",
      "['山田花子', 'さんま', '半次', '上岡', '鉄平', 'ショージ', '山ちゃん', 'いかり', '昇太', '土田晃之']\n"
     ]
    }
   ],
   "source": [
    "feature_vector = {\n",
    "    sn: tweetanalysis.get_feature_vector(\n",
    "        tweetanalysis.get_tweets_score(sn, expectation, model)[0],\n",
    "        model\n",
    "    )\n",
    "    for sn in ['******', 'ha_chu', 'ariyoshihiroiki']\n",
    "}\n",
    "\n",
    "# 単語,コサイン類似度のtupleのlistが返されるので単語だけのlistにしている。\n",
    "\n",
    "for sn in feature_vector:\n",
    "    print(sn)\n",
    "    print([\n",
    "     w for w, s in model.wv.most_similar([feature_vector[sn]])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 入力 7\n",
    "pp. 61-62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "\n",
    "users = ['asahi', 'mainichi','Yomiuri_Online', 'nikkei',\n",
    " 'nikkan_gendai', 'sakigake', 'toonippo']\n",
    "for sn in users:\n",
    "    feature_vector[sn] = tweetanalysis.get_feature_vector(\n",
    "        tweetanalysis.get_tweets_score(sn, expectation, model)[0],\n",
    "        model\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>朝</th>\n",
       "      <th>毎</th>\n",
       "      <th>読</th>\n",
       "      <th>経</th>\n",
       "      <th>ゲ</th>\n",
       "      <th>秋</th>\n",
       "      <th>東奥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>朝</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971345</td>\n",
       "      <td>0.941197</td>\n",
       "      <td>0.778815</td>\n",
       "      <td>0.881053</td>\n",
       "      <td>0.763461</td>\n",
       "      <td>0.758345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>毎</th>\n",
       "      <td>0.971345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944885</td>\n",
       "      <td>0.821602</td>\n",
       "      <td>0.884132</td>\n",
       "      <td>0.757335</td>\n",
       "      <td>0.735295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>読</th>\n",
       "      <td>0.941197</td>\n",
       "      <td>0.944885</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.775966</td>\n",
       "      <td>0.844696</td>\n",
       "      <td>0.786891</td>\n",
       "      <td>0.784721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>経</th>\n",
       "      <td>0.778815</td>\n",
       "      <td>0.821602</td>\n",
       "      <td>0.775966</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669701</td>\n",
       "      <td>0.649386</td>\n",
       "      <td>0.587322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ゲ</th>\n",
       "      <td>0.881053</td>\n",
       "      <td>0.884132</td>\n",
       "      <td>0.844696</td>\n",
       "      <td>0.669701</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.613522</td>\n",
       "      <td>0.618513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>秋</th>\n",
       "      <td>0.763461</td>\n",
       "      <td>0.757335</td>\n",
       "      <td>0.786891</td>\n",
       "      <td>0.649386</td>\n",
       "      <td>0.613522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>東奥</th>\n",
       "      <td>0.758345</td>\n",
       "      <td>0.735295</td>\n",
       "      <td>0.784721</td>\n",
       "      <td>0.587322</td>\n",
       "      <td>0.618513</td>\n",
       "      <td>0.976752</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           朝         毎         読         経         ゲ         秋        東奥\n",
       "朝   1.000000  0.971345  0.941197  0.778815  0.881053  0.763461  0.758345\n",
       "毎   0.971345  1.000000  0.944885  0.821602  0.884132  0.757335  0.735295\n",
       "読   0.941197  0.944885  1.000000  0.775966  0.844696  0.786891  0.784721\n",
       "経   0.778815  0.821602  0.775966  1.000000  0.669701  0.649386  0.587322\n",
       "ゲ   0.881053  0.884132  0.844696  0.669701  1.000000  0.613522  0.618513\n",
       "秋   0.763461  0.757335  0.786891  0.649386  0.613522  1.000000  0.976752\n",
       "東奥  0.758345  0.735295  0.784721  0.587322  0.618513  0.976752  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tweetanalysis, numpy as np\n",
    "\n",
    "users = ['asahi', 'mainichi','Yomiuri_Online', 'nikkei',\n",
    " 'nikkan_gendai', 'sakigake', 'toonippo']\n",
    "users2 = ['朝','毎', '読', '経', 'ゲ', '秋', '東奥']\n",
    "\n",
    "# ベクトルのlistを2次元配列に格納\n",
    "vectors = np.array([\n",
    "    tweetanalysis.normalize(feature_vector[u]) for u in users\n",
    "])\n",
    "\n",
    "# コサイン類似度の行列を計算\n",
    "news_similarity = pd.DataFrame(\n",
    "    np.einsum('ik,jk->ij', vectors, vectors),\n",
    "    columns = users2,\n",
    "    index = users2\n",
    ")\n",
    "display(news_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 入力 8\n",
    "p. 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>朝</th>\n",
       "      <th>毎</th>\n",
       "      <th>読</th>\n",
       "      <th>経</th>\n",
       "      <th>ゲ</th>\n",
       "      <th>秋</th>\n",
       "      <th>東奥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>朝</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.613484</td>\n",
       "      <td>0.257842</td>\n",
       "      <td>-0.183654</td>\n",
       "      <td>0.301299</td>\n",
       "      <td>-0.608063</td>\n",
       "      <td>-0.526931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>毎</th>\n",
       "      <td>0.613484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.278400</td>\n",
       "      <td>0.078026</td>\n",
       "      <td>0.314666</td>\n",
       "      <td>-0.702628</td>\n",
       "      <td>-0.739747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>読</th>\n",
       "      <td>0.257842</td>\n",
       "      <td>0.278400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.182154</td>\n",
       "      <td>0.050742</td>\n",
       "      <td>-0.404511</td>\n",
       "      <td>-0.314495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>経</th>\n",
       "      <td>-0.183654</td>\n",
       "      <td>0.078026</td>\n",
       "      <td>-0.182154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.197683</td>\n",
       "      <td>-0.296688</td>\n",
       "      <td>-0.458325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ゲ</th>\n",
       "      <td>0.301299</td>\n",
       "      <td>0.314666</td>\n",
       "      <td>0.050742</td>\n",
       "      <td>-0.197683</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.621898</td>\n",
       "      <td>-0.522201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>秋</th>\n",
       "      <td>-0.608063</td>\n",
       "      <td>-0.702628</td>\n",
       "      <td>-0.404511</td>\n",
       "      <td>-0.296688</td>\n",
       "      <td>-0.621898</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>東奥</th>\n",
       "      <td>-0.526931</td>\n",
       "      <td>-0.739747</td>\n",
       "      <td>-0.314495</td>\n",
       "      <td>-0.458325</td>\n",
       "      <td>-0.522201</td>\n",
       "      <td>0.906468</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           朝         毎         読         経         ゲ         秋        東奥\n",
       "朝   1.000000  0.613484  0.257842 -0.183654  0.301299 -0.608063 -0.526931\n",
       "毎   0.613484  1.000000  0.278400  0.078026  0.314666 -0.702628 -0.739747\n",
       "読   0.257842  0.278400  1.000000 -0.182154  0.050742 -0.404511 -0.314495\n",
       "経  -0.183654  0.078026 -0.182154  1.000000 -0.197683 -0.296688 -0.458325\n",
       "ゲ   0.301299  0.314666  0.050742 -0.197683  1.000000 -0.621898 -0.522201\n",
       "秋  -0.608063 -0.702628 -0.404511 -0.296688 -0.621898  1.000000  0.906468\n",
       "東奥 -0.526931 -0.739747 -0.314495 -0.458325 -0.522201  0.906468  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# vectors.mean(0)が全新聞社の平均特徴量ベクトル\n",
    "# 引いた結果をそれぞれ正規化\n",
    "vectors2 = tweetanalysis.normalize(vectors - vectors.mean(0), 1)\n",
    "\n",
    "# 原点を移動したベクトルにアクセスしやすくなるようにdictを準備\n",
    "feature_vector2 = {k:v for k,v in zip(users, vectors2)}\n",
    "\n",
    "\n",
    "# コサイン類似度の行列を計算\n",
    "news_similarity2 = pd.DataFrame(\n",
    "    np.einsum('ik,jk->ij', vectors2, vectors2),\n",
    "    columns = users2,\n",
    "    index = users2\n",
    ")\n",
    "display(news_similarity2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 入力 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1とWの各ベクトルのコサイン類似度\n",
      "[ 0.10449215  0.08208558 -0.10198595 -0.05087476  0.01623713]\n",
      "V2とWの各ベクトルのコサイン類似度\n",
      "[ -3.51281504e-17  -1.23065417e-17  -9.19403442e-17   7.89299182e-17\n",
      "   5.20417043e-18]\n"
     ]
    }
   ],
   "source": [
    "# ベクトルの次元\n",
    "M = 50\n",
    "\n",
    "# 引き去りたいベクトルの数 N<M\n",
    "N = 5\n",
    "\n",
    "# N個のM次元ベクトルをランダムで生成\n",
    "W = np.random.normal(size=(M,N))\n",
    "\n",
    "# 元のベクトルランダムで生成\n",
    "V1 = np.random.normal(size=M)\n",
    "\n",
    "# QR分解 デフォルトではQは N 列目までの部分のみ返される。\n",
    "q,r = np.linalg.qr(W)\n",
    "\n",
    "# Qのそれぞれの列ベクトル成分と内積をとって、\n",
    "# それをそれぞれの列ベクトルに足した成分を引いている。\n",
    "# V2がW[:,x]とそれぞれ独立(内積が0=>コサイン類似度が0)なベクトルとなっている。\n",
    "V2 = V1 - np.einsum('i,ij,kj->k', V1, q, q)\n",
    "\n",
    "import tweetanalysis\n",
    "\n",
    "# コサイン類似度を計算してみる。\n",
    "W = tweetanalysis.normalize( W)\n",
    "V1 = tweetanalysis.normalize(V1)\n",
    "V2 = tweetanalysis.normalize(V2)\n",
    "\n",
    "print(\"V1とWの各ベクトルのコサイン類似度\")\n",
    "print(V1.dot(W))\n",
    "\n",
    "print(\"V2とWの各ベクトルのコサイン類似度\")\n",
    "print(V2.dot(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 入力 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most_similar\n",
      "[('流れ弾', 0.6762729287147522), ('自動車事故', 0.6698358654975891), ('結審', 0.6674159169197083), ('事故', 0.6670531034469604), ('凶行', 0.6590184569358826), ('事故死', 0.658760666847229), ('自供', 0.6572832465171814), ('銃撃', 0.6542375683784485), ('ギロチン', 0.6534814834594727), ('負傷', 0.6520446538925171)]\n",
      "orthogoal_words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('流れ弾', 0.6762729287147522),\n",
       " ('離婚', 0.5758596062660217),\n",
       " ('赤の広場', 0.5547539591789246),\n",
       " ('特別ルール', 0.5496065020561218),\n",
       " ('ハウツー', 0.5097163319587708),\n",
       " ('列車', 0.5745046138763428),\n",
       " ('ガルバルディ', 0.5364318490028381),\n",
       " ('取り下げ', 0.5334466099739075),\n",
       " ('欲鬼', 0.49935439229011536),\n",
       " ('13センチ', 0.5212986469268799)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 通常の mosts_imilar 関数による類似語\n",
    "print(\"most_similar\")\n",
    "print(\n",
    "    model.wv.most_similar([\n",
    "        feature_vector2['asahi'] + feature_vector2['Yomiuri_Online']\n",
    "    ])\n",
    ")\n",
    "\n",
    "# 直交成分からの類似語\n",
    "print(\"orthogoal_words\")\n",
    "display(\n",
    "    tweetanalysis.orthogonal_words(\n",
    "        feature_vector2['Yomiuri_Online'] + feature_vector2['asahi'],\n",
    "        model\n",
    "     )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
